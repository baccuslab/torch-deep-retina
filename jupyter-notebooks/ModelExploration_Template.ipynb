{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import h5py as h5\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from torchdeepretina.models import *\n",
    "#import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from   torchdeepretina.physiology import Physio\n",
    "import torchdeepretina.intracellular as intracellular\n",
    "import torchdeepretina.batch_compute as bc\n",
    "import torchdeepretina.retinal_phenomena as rp\n",
    "import torchdeepretina.stimuli as stimuli\n",
    "from   torchdeepretina.sta_ascent import STAAscent\n",
    "from   torchdeepretina.deepretina_loader import loadexpt\n",
    "import pyret.filtertools as ft\n",
    "import scipy\n",
    "import scipy.cluster as cluster\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import resource\n",
    "import time\n",
    "import math\n",
    "\n",
    "def normalize(x):\n",
    "    return (x-x.mean())/(x.std()+1e-7)\n",
    "\n",
    "def retinal_phenomena_figs(bn_cnn):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    rp.step_response(bn_cnn)\n",
    "    rp.osr(bn_cnn)\n",
    "    rp.reversing_grating(bn_cnn)\n",
    "    rp.contrast_adaptation(bn_cnn, .35, .05)\n",
    "    rp.motion_anticipation(bn_cnn)\n",
    "    \n",
    "#If you want to use stimulus that isnt just boxes\n",
    "def prepare_stim(stim, stim_type):\n",
    "    if stim_type == 'boxes':\n",
    "        return 2*stim - 1\n",
    "    elif stim_type == 'flashes':\n",
    "        stim = stim.reshape(stim.shape[0], 1, 1)\n",
    "        return np.broadcast_to(stim, (stim.shape[0], 38, 38))\n",
    "    elif stim_type == 'movingbar':\n",
    "        stim = block_reduce(stim, (1,6), func=np.mean)\n",
    "        stim = pyret.stimulustools.upsample(stim.reshape(stim.shape[0], stim.shape[1], 1), 5)[0]\n",
    "        return np.broadcast_to(stim, (stim.shape[0], stim.shape[1], stim.shape[1]))\n",
    "    elif stim_type == 'lines':\n",
    "        stim_averaged = np.apply_along_axis(lambda m: np.convolve(m, 0.5*np.ones((2,)), mode='same'), \n",
    "                                            axis=1, arr=stim)\n",
    "        stim = stim_averaged[:,::2]\n",
    "        # now stack stimulus to convert 1d to 2d spatial stimulus\n",
    "        return stim.reshape(-1,1,stim.shape[-1]).repeat(stim.shape[-1], axis=1)\n",
    "    else:\n",
    "        print(\"Invalid stim type\")\n",
    "        assert False\n",
    "    \n",
    "def index_of(arg, arr):\n",
    "    for i in range(len(arr)):\n",
    "        if arg == arr[i]:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def load_model(folder, pth):\n",
    "    hyps=get_hyps(folder)\n",
    "    try:\n",
    "        hyps['model_type'] = hyps['model_type'].split(\".\")[-1].split(\"\\'\")[0].strip()\n",
    "        hyps['model_type'] = globals()[hyps['model_type']]\n",
    "        bn_cnn = hyps['model_type'](**temp['model_hyps'])\n",
    "    except Exception as e:\n",
    "        model_hyps = {\"n_units\":5,\"noise\":float(hyps['noise']),\"bias\":bool(hyps['bias'])}\n",
    "        if \"chans\" in hyps:\n",
    "            model_hyps['chans'] = [int(x) for x in \n",
    "                                   hyps['chans'].replace(\"[\", \"\").replace(\"]\", \"\").strip().split(\",\")]\n",
    "        if \"adapt_gauss\" in hyps:\n",
    "            model_hyps['adapt_gauss'] = hyps['adapt_gauss']\n",
    "        fn_args = set(hyps['model_type'].__init__.__code__.co_varnames)\n",
    "        for k in model_hyps.keys():\n",
    "            if k not in fn_args:\n",
    "                del model_hyps[k]\n",
    "        bn_cnn = hyps['model_type'](**model_hyps)\n",
    "    return bn_cnn\n",
    "\n",
    "def get_hyps(folder):\n",
    "    hyps = dict()\n",
    "    with open(os.path.join(\"../training_scripts/\", folder, \"hyperparams.txt\")) as f:\n",
    "        for line in f:\n",
    "            if \"(\" not in line and \")\" not in line:\n",
    "                splt = line.strip().split(\":\")\n",
    "                if len(splt) > 1:\n",
    "                    hyps[splt[0]] = splt[1]\n",
    "    return hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "# num_pots stores the number of cells per stimulus\n",
    "# mem_pots stores the membrane potential\n",
    "# psst, you can find the \"data\" folder in /home/grantsrb on deepretina server\n",
    "# psssst, note the additional ../ added to each path in files\n",
    "root_path = \"~/interneuron_data/\"\n",
    "files = ['bipolars_late_2012.h5', 'bipolars_early_2012.h5', 'amacrines_early_2012.h5', \n",
    "         'amacrines_late_2012.h5', 'horizontals_early_2012.h5', 'horizontals_late_2012.h5']\n",
    "files = [os.path.expanduser(root_path + name) for name in files]\n",
    "file_ids = []\n",
    "for f in files:\n",
    "    file_ids.append(re.split('_|\\.', f)[0])\n",
    "filter_length = 40\n",
    "window_size = 2\n",
    "num_pots = []\n",
    "stims = dict()\n",
    "mem_pots = dict()\n",
    "keys_to_use = {\"boxes\"}\n",
    "for fi in files:\n",
    "    with h5.File(fi, 'r') as f:\n",
    "        for k in f.keys():\n",
    "            if k in keys_to_use:\n",
    "                if k not in stims:\n",
    "                    stims[k] = []\n",
    "                if k not in mem_pots:\n",
    "                    mem_pots[k] = []\n",
    "                try:\n",
    "                    stims[k].append(prepare_stim(np.asarray(f[k+'/stimuli']), k))\n",
    "                    mem_pots[k].append(np.asarray(f[k]['detrended_membrane_potential'])[:, filter_length:])\n",
    "                except:\n",
    "                    print(\"stim error at\", k)\n",
    "        num = np.array(f['boxes/detrended_membrane_potential'].shape[0])\n",
    "        num_pots.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_folder = \"absbnbncnn\"\n",
    "exp_folder = \"../training_scripts/\"+grand_folder\n",
    "_, model_folders, _ = next(os.walk(exp_folder))\n",
    "for i,f in enumerate(model_folders):\n",
    "    model_folders[i] = grand_folder + \"/\" + f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folders = sorted(model_folders)\n",
    "print(\"\\n\".join(model_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../training_scripts/\"+model_folders[0]+\"/test_epoch_0.pth\"\n",
    "try:\n",
    "    with open(file, \"rb\") as fd:\n",
    "        temp = torch.load(fd)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    temp['model']\n",
    "except Exception as e:\n",
    "    model = load_model(model_folders[0], temp)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_idxs = [0, 6]\n",
    "bn_idxs = [2,8]\n",
    "sta_idx = 6\n",
    "linear_idx = 11\n",
    "linear_shape = (5,24,26,26)\n",
    "bn_shapes = [(8,36,36), (24,26,26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = \"all\"\n",
    "dataset = '15-10-07'\n",
    "try:\n",
    "    norm_stats = [temp['norm_stats']['mean'], temp['norm_stats']['std']]\n",
    "except:\n",
    "    norm_stats = [51.49175, 53.62663279042969]\n",
    "test_data = loadexpt(dataset,cells,'naturalscene','test',40,0, norm_stats=norm_stats)\n",
    "test_y = torch.FloatTensor(test_data.y)\n",
    "test_x = torch.FloatTensor(test_data.X)\n",
    "test_x.requires_grad=True\n",
    "loss_fxn = torch.nn.PoissonNLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500 # For grad clustering\n",
    "kmeans_k = 8\n",
    "sta_ascent_obj = STAAscent()\n",
    "stim_shape = [40, 50, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for folder in model_folders:\n",
    "    print(\"Evaluating\", folder)\n",
    "    for i in range(300):\n",
    "        file = \"../training_scripts/\"+folder+\"/test_epoch_{0}.pth\".format(i)\n",
    "        try:\n",
    "            with open(file, \"rb\") as fd:\n",
    "                temp = torch.load(fd)\n",
    "            data = temp\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    try:\n",
    "        model = data['model']\n",
    "    except Exception as e:\n",
    "        model = load_model(folder, data)\n",
    "    model.load_state_dict(data['model_state_dict'])\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    # Retinal Phenomena\n",
    "#     retinal_phenomena_figs(model)\n",
    "    \n",
    "    # Conv Filter visualizations\n",
    "    for k,idx in enumerate(conv_idxs[:1]):\n",
    "        module = model.sequential[idx]\n",
    "        ps = list(module.parameters())\n",
    "        p = ps[0].cpu().detach().numpy()\n",
    "        fig=plt.figure(figsize=(18, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        fig.suptitle(\"Conv \" + str(k+1) + \" Filters\", fontsize=16)\n",
    "        for i in range(p.shape[0]):\n",
    "            std = np.std(p[i])\n",
    "            mean = np.mean(p[i])\n",
    "            vmin = mean - 4*std\n",
    "            vmax = mean + 4*std\n",
    "            n_slices = 8\n",
    "            for j in range(n_slices):\n",
    "                plt.subplot(p.shape[0],n_slices,1 + i*n_slices+j)\n",
    "                plt.imshow(p[i,int(p.shape[1]*j/n_slices),:,:], vmin=vmin, vmax=vmax)\n",
    "        plt.show()\n",
    "\n",
    "        # Rank decomp\n",
    "        fig = plt.figure(figsize=(18,6))\n",
    "        fig.suptitle(\"Rank 1 Decomp of each filter\", fontsize=16)\n",
    "        for i in range(p.shape[0]):\n",
    "            spatial_model, temporal_model = ft.decompose(p[i])\n",
    "            plt.subplot(2,p.shape[0], i+1)\n",
    "            plt.imshow(spatial_model, cmap = 'seismic', clim=[-np.max(abs(spatial_model)),\n",
    "                                                                   np.max(abs(spatial_model))])\n",
    "            plt.subplot(2,p.shape[0], i+1 + p.shape[0])\n",
    "            plt.plot(temporal_model)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    # Receptive field samples\n",
    "    filter_length = 40\n",
    "    conv_layers = [\"sequential.\" + str(x) for x in conv_idxs]\n",
    "    stimulus_num = 2\n",
    "    stimulus = stims['boxes'][stimulus_num]\n",
    "    padded_stim = intracellular.pad_to_edge(scipy.stats.zscore(stimulus))\n",
    "    unit_step = 8\n",
    "    model_response = bc.batch_compute_model_response(stimuli.concat(padded_stim), model, batch_size, \n",
    "                                                            insp_keys=set(conv_layers))\n",
    "    # Plot the receptive fields for model cells layer 1\n",
    "    cl = conv_layers[0]\n",
    "    for c in range(model_response[cl].shape[1]):\n",
    "        figidx = 0\n",
    "        fig=plt.figure(figsize=(18, 18), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        fig.suptitle(cl + \" Filter \" + str(c), fontsize=16)\n",
    "        for row in range(0,model_response[cl].shape[2],unit_step):\n",
    "            for col in range(0,model_response[cl].shape[3],unit_step):\n",
    "                figidx += 1\n",
    "                try:\n",
    "                    plt.subplot(int(np.ceil(model_response[cl].shape[2]/unit_step)), \n",
    "                                int(np.ceil(model_response[cl].shape[3]/unit_step)), \n",
    "                                figidx)\n",
    "                    model_cell_response = model_response[cl][:, c, row, col]\n",
    "                    rc_model, lags_model = ft.revcorr(scipy.stats.zscore(stimulus[filter_length:]), model_cell_response, \n",
    "                                                      nsamples_before=0, nsamples_after=filter_length)\n",
    "\n",
    "                    spatial_model, temporal_model = ft.decompose(rc_model)\n",
    "                    img = plt.imshow(spatial_model.squeeze(), cmap = 'seismic', clim=[-np.max(abs(spatial_model)), \n",
    "                                                                       np.max(abs(spatial_model))])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"model_response[cl].shape\", model_response[cl].shape)\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot the receptive fields for model cells layer 2\n",
    "    cl = conv_layers[1]\n",
    "    s = intracellular.pad_to_edge(scipy.stats.zscore(stimulus[filter_length:]))\n",
    "    for c in range(model_response[cl].shape[1]):\n",
    "        for row in range(0,model_response[cl].shape[2],unit_step):\n",
    "            figidx = 0\n",
    "            n_cols = int(np.ceil(model_response[cl].shape[3]/unit_step))\n",
    "            fig=plt.figure(figsize=(18, 7), dpi= 80, facecolor='w', edgecolor='k')\n",
    "            fig.suptitle(cl + \" Filter \" + str(c), fontsize=16)\n",
    "            for col in range(0,model_response[cl].shape[3],unit_step):\n",
    "                figidx += 1\n",
    "                try:\n",
    "                    plt.subplot(2, n_cols, figidx)\n",
    "                    model_cell_response = model_response[cl][:, c, row, col]\n",
    "\n",
    "                    rc_model, lags_model = ft.revcorr(s, model_cell_response, \n",
    "                                                      nsamples_before=0, nsamples_after=filter_length)\n",
    "                    spatial_model, temporal_model = ft.decompose(rc_model)\n",
    "                    img = plt.imshow(spatial_model.squeeze(), cmap = 'seismic', clim=[-np.max(abs(spatial_model)), \n",
    "                                                                       np.max(abs(spatial_model))])\n",
    "                    plt.subplot(2, n_cols, figidx+n_cols)                    \n",
    "                    sta_img = sta_ascent_obj.sta_ascent(model, cl, units=[(c,row,col)], \n",
    "                                                        n_epochs=5000, constraint=.3)\n",
    "                    spatial_model, temporal_model = ft.decompose(sta_img.squeeze())\n",
    "                    img = plt.imshow(spatial_model.squeeze(), cmap=\"seismic\", clim=[-np.max(abs(spatial_model)), \n",
    "                                                                       np.max(abs(spatial_model))])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"model_response[cl].shape\", model_response[cl].shape)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    \n",
    "    ## Batchnorm vis\n",
    "    for k, idx in enumerate(bn_idxs):\n",
    "        module = model.sequential[idx]\n",
    "        ps = list(module.named_parameters())\n",
    "        p = ps[0][1].cpu().detach().numpy().reshape(bn_shapes[k])\n",
    "        fig=plt.figure(figsize=(18, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        fig.suptitle(\"BatchNorm \" + str(k+1) + \" Filters\", fontsize=16)\n",
    "        for i in range(p.shape[0]):\n",
    "            std = np.std(p[i])\n",
    "            mean = np.mean(p[i])\n",
    "            vmin = mean - 1.9*std\n",
    "            vmax = mean + 1.9*std\n",
    "            plt.subplot(1,p.shape[0], 1+i)\n",
    "            plt.imshow(p[i], vmin=vmin, vmax=vmax)\n",
    "        plt.show()\n",
    "    \n",
    "    ## Linear Vis\n",
    "    module = model.sequential[linear_idx]\n",
    "    ps = list(module.named_parameters())\n",
    "    p = ps[0][1].cpu().detach().numpy().reshape(linear_shape)\n",
    "    fig=plt.figure(figsize=(18, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(\"Linear Filters\", fontsize=16)\n",
    "    std = np.std(p)\n",
    "    mean = np.mean(p)\n",
    "    vmin = mean - 1.9*std\n",
    "    vmax = mean + 1.9*std\n",
    "    for j in range(linear_shape[0]):        \n",
    "        for i in range(linear_shape[1]):\n",
    "            plt.subplot(linear_shape[0],linear_shape[1], j*linear_shape[1]+i+1)\n",
    "            plt.imshow(p[j,i], vmin=vmin, vmax=vmax)\n",
    "    plt.show()\n",
    "    \n",
    "    ## Gradient cluster\n",
    "    for i in tqdm(range(0,test_x.shape[0], batch_size)):\n",
    "        batch_x = test_x[i:i+batch_size].to(DEVICE)\n",
    "        batch_y = test_y[i:i+batch_size].to(DEVICE)\n",
    "        preds = model(batch_x)\n",
    "        loss = loss_fxn(preds, batch_y)\n",
    "        loss.backward()\n",
    "    test_x.grad.data /= int(test_x.shape[0]//batch_size)\n",
    "    grad = test_x.grad.data\n",
    "    grad = grad.view(grad.shape[0], -1).detach().cpu().numpy()\n",
    "    whitened = cluster.vq.whiten(grad)\n",
    "    print(\"Beginning Cluster\")\n",
    "    clust,distort = cluster.vq.kmeans(whitened, kmeans_k)\n",
    "    clust = clust.reshape(tuple([-1] + stim_shape))\n",
    "    fig=plt.figure(figsize=(18, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(\"Gradient Cluster with \" + str(kmeans_k)+\" means\", fontsize=16)\n",
    "    for i in range(kmeans_k):\n",
    "        std = np.std(clust[i])\n",
    "        mean = np.mean(clust[i])\n",
    "        vmin = mean - 1.9*std\n",
    "        vmax = mean + 1.9*std\n",
    "        n_slices = 8\n",
    "        for j in range(n_slices):\n",
    "            plt.subplot(kmeans_k,n_slices,1 + i*n_slices+j)\n",
    "            plt.imshow(clust[i,int(stim_shape[0]*j/n_slices),:,:], vmin=vmin, vmax=vmax)\n",
    "    plt.show()\n",
    "    ## Rank decomp\n",
    "    fig = plt.figure(figsize=(18,6))\n",
    "    fig.suptitle(\"Rank 1 Decomp of clusters\", fontsize=16)\n",
    "    for i in range(clust.shape[0]):\n",
    "        spatial_model, temporal_model = ft.decompose(clust[i])\n",
    "        plt.subplot(2,clust.shape[0], i+1)\n",
    "        plt.imshow(spatial_model, cmap = 'seismic', clim=[-np.max(abs(spatial_model)),\n",
    "                                                               np.max(abs(spatial_model))])\n",
    "        plt.subplot(2,clust.shape[0], i+1 + clust.shape[0])\n",
    "        plt.plot(temporal_model)\n",
    "    plt.show()\n",
    "        \n",
    "    print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
