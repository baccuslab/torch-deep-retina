{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import h5py as h5\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../\")\n",
    "from models import PracticalBNCNN, NormedBNCNN, DalesBNCNN, DalesSSCNN, SSCNN, BNCNN, PracticalBNCNN, DalesHybrid, DalesSkipBNCNN, SkipBNBNCNN\n",
    "#import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.physiology import Physio\n",
    "import utils.intracellular as intracellular\n",
    "import utils.batch_compute as bc\n",
    "import utils.retinal_phenomena as rp\n",
    "import utils.stimuli as stimuli\n",
    "from utils.sta_ascent import STAAscent\n",
    "from utils.deepretina_loader import loadexpt\n",
    "import pyret.filtertools as ft\n",
    "import scipy\n",
    "import scipy.cluster as cluster\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import resource\n",
    "import time\n",
    "import math\n",
    "\n",
    "def normalize(x):\n",
    "    return (x-x.mean())/(x.std()+1e-7)\n",
    "\n",
    "def retinal_phenomena_figs(bn_cnn):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    rp.step_response(bn_cnn)\n",
    "    rp.osr(bn_cnn)\n",
    "    rp.reversing_grating(bn_cnn)\n",
    "    rp.contrast_adaptation(bn_cnn, .35, .05)\n",
    "    rp.motion_anticipation(bn_cnn)\n",
    "    \n",
    "#If you want to use stimulus that isnt just boxes\n",
    "def prepare_stim(stimuli, stim_type):\n",
    "    if stim_type == 'boxes':\n",
    "        return stimuli\n",
    "    elif stim_type == 'flashes':\n",
    "        stim = stimuli.reshape(stimuli.shape[0], 1, 1)\n",
    "        return np.broadcast_to(stim, (stim.shape[0], 38, 38))\n",
    "    elif stim_type == 'movingbar':\n",
    "        stim = block_reduce(stimuli, (1,6), func=np.mean)\n",
    "        stim = pyret.stimulustools.upsample(stim.reshape(stim.shape[0], stim.shape[1], 1), 5)[0]\n",
    "        return np.broadcast_to(stim, (stim.shape[0], stim.shape[1], stim.shape[1]))\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def index_of(arg, arr):\n",
    "    for i in range(len(arr)):\n",
    "        if arg == arr[i]:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_folder = \"bncnn\"\n",
    "exp_folder = \"../training_scripts/\"+grand_folder\n",
    "_, model_folders, _ = next(os.walk(exp_folder))\n",
    "for i,f in enumerate(model_folders):\n",
    "    model_folders[i] = grand_folder + \"/\" + f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folders = sorted(model_folders)\n",
    "print(\"\\n\".join(model_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = model_folders[0]\n",
    "for i in range(250):\n",
    "        file = \"../training_scripts/\"+folder+\"/test_epoch_{0}.pth\".format(i)\n",
    "        try:\n",
    "            with open(file, \"rb\") as fd:\n",
    "                temp = torch.load(fd)\n",
    "        except:\n",
    "            break\n",
    "temp['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_idxs = [0, 6]\n",
    "bn_idxs = [2,8]\n",
    "linear_idx = 11\n",
    "linear_shape = (5,8,26,26)\n",
    "bn_shapes = [(8,36,36), (8,26,26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = \"all\"\n",
    "dataset = '15-10-07'\n",
    "try:\n",
    "    norm_stats = [temp['norm_stats']['mean'], temp['norm_stats']['std']]\n",
    "except:\n",
    "    norm_stats = [51.49175, 53.62663279042969]\n",
    "test_data = loadexpt(dataset,cells,'naturalscene','test',40,0, norm_stats=norm_stats)\n",
    "test_y = torch.FloatTensor(test_data.y)\n",
    "test_x = torch.FloatTensor(test_data.X)\n",
    "test_x.requires_grad=True\n",
    "loss_fxn = torch.nn.PoissonNLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 500 # For grad clustering\n",
    "kmeans_k = 8\n",
    "sta_ascent_obj = STAAscent()\n",
    "stim_shape = [40, 50, 50]\n",
    "\n",
    "for folder in model_folders:\n",
    "    print(\"Evaluating\", folder)\n",
    "    for i in range(300):\n",
    "        file = \"../training_scripts/\"+folder+\"/test_epoch_{0}.pth\".format(i)\n",
    "        try:\n",
    "            with open(file, \"rb\") as fd:\n",
    "                temp = torch.load(fd)\n",
    "        except:\n",
    "            break\n",
    "    model = temp['model']\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    # Retinal Phenomena\n",
    "#     retinal_phenomena_figs(model)\n",
    "    \n",
    "    # Conv Filter visualizations\n",
    "    for k,idx in enumerate(conv_idxs):\n",
    "        module = temp['model'].sequential[idx]\n",
    "        ps = list(module.parameters())\n",
    "        p = ps[0].cpu().detach().numpy()\n",
    "        fig=plt.figure(figsize=(18, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        fig.suptitle(\"Conv \" + str(k+1) + \" Filters\", fontsize=16)\n",
    "        for i in range(p.shape[0]):\n",
    "            std = np.std(p[i])\n",
    "            mean = np.mean(p[i])\n",
    "            vmin = mean - 4*std\n",
    "            vmax = mean + 4*std\n",
    "            n_slices = 8\n",
    "            for j in range(n_slices):\n",
    "                plt.subplot(p.shape[0],n_slices,1 + i*n_slices+j)\n",
    "                plt.imshow(p[i,int(p.shape[1]*j/n_slices),:,:], vmin=vmin, vmax=vmax)\n",
    "        plt.show()\n",
    "\n",
    "        # Rank decomp\n",
    "        fig = plt.figure(figsize=(18,6))\n",
    "        fig.suptitle(\"Rank 1 Decomp of each filter\", fontsize=16)\n",
    "        for i in range(p.shape[0]):\n",
    "            spatial_model, temporal_model = ft.decompose(p[i])\n",
    "            plt.subplot(2,p.shape[0], i+1)\n",
    "            plt.imshow(spatial_model, cmap = 'seismic', clim=[-np.max(abs(spatial_model)),\n",
    "                                                                   np.max(abs(spatial_model))])\n",
    "            plt.subplot(2,p.shape[0], i+1 + p.shape[0])\n",
    "            plt.plot(temporal_model)\n",
    "        plt.show()\n",
    "    \n",
    "    # Receptive field samples\n",
    "    filter_length = 40\n",
    "    conv_layers = [\"sequential.\" + str(x) for x in conv_idxs]\n",
    "    stimulus = test_data.X[:1000]\n",
    "    unit_step = 4\n",
    "    model_response = bc.batch_compute_model_response(stimulus, model, batch_size, \n",
    "                                                            insp_keys=set(conv_layers))\n",
    "    # Plot the receptive fields for model cells\n",
    "    for cl in conv_layers:\n",
    "        for c in range(model_response[cl].shape[1]):\n",
    "            fig=plt.figure(figsize=(18, 18), dpi= 80, facecolor='w', edgecolor='k')\n",
    "            fig.suptitle(cl + \" Filter \" + str(c), fontsize=16)\n",
    "            for row in range(0,model_response[cl].shape[2],unit_step):\n",
    "                for col in range(0,model_response[cl].shape[3],unit_step):\n",
    "                    plt.subplot(model_response[cl].shape[2]//unit_step, model_response[cl].shape[3]//unit_step, \n",
    "                                                row*model_response[cl].shape[3] + col +1)\n",
    "                    model_cell_response = model_response[cl][:, c, row, col]\n",
    "                    rc_model, lags_model = ft.revcorr(stimulus[:,0], model_cell_response, \n",
    "                                                      nsamples_before=0, nsamples_after=filter_length)\n",
    "                    spatial_model, temporal_model = ft.decompose(rc_model)\n",
    "                    img = plt.imshow(spatial_model.squeeze(), cmap = 'seismic', clim=[-np.max(abs(spatial_model)), \n",
    "                                                                       np.max(abs(spatial_model))])\n",
    "        plt.show()\n",
    "    \n",
    "    ## Batchnorm vis\n",
    "    for k, idx in enumerate(bn_idxs):\n",
    "        module = temp['model'].sequential[idx]\n",
    "        ps = list(module.named_parameters())\n",
    "        p = ps[0][1].cpu().detach().numpy().reshape(bn_shapes[k])\n",
    "        fig=plt.figure(figsize=(18, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        fig.suptitle(\"BatchNorm \" + str(k+1) + \" Filters\", fontsize=16)\n",
    "        for i in range(p.shape[0]):\n",
    "            std = np.std(p[i])\n",
    "            mean = np.mean(p[i])\n",
    "            vmin = mean - 1.9*std\n",
    "            vmax = mean + 1.9*std\n",
    "            plt.subplot(1,p.shape[0], 1+i)\n",
    "            plt.imshow(p[i], vmin=vmin, vmax=vmax)\n",
    "        plt.show()\n",
    "    \n",
    "    ## Linear Vis\n",
    "    module = temp['model'].sequential[linear_idx]\n",
    "    ps = list(module.named_parameters())\n",
    "    p = ps[0][1].cpu().detach().numpy().reshape(linear_shape)\n",
    "    fig=plt.figure(figsize=(18, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(\"Linear Filters\", fontsize=16)\n",
    "    std = np.std(p)\n",
    "    mean = np.mean(p)\n",
    "    vmin = mean - 1.9*std\n",
    "    vmax = mean + 1.9*std\n",
    "    for j in range(linear_shape[0]):        \n",
    "        for i in range(linear_shape[1]):\n",
    "            plt.subplot(linear_shape[0],linear_shape[1], j*linear_shape[1]+i+1)\n",
    "            plt.imshow(p[j,i], vmin=vmin, vmax=vmax)\n",
    "    plt.show()\n",
    "    \n",
    "    ## Gradient cluster\n",
    "    for i in tqdm(range(0,test_x.shape[0], batch_size)):\n",
    "        batch_x = test_x[i:i+batch_size].to(DEVICE)\n",
    "        batch_y = test_y[i:i+batch_size].to(DEVICE)\n",
    "        preds = model(batch_x)\n",
    "        loss = loss_fxn(preds, batch_y)\n",
    "        loss.backward()\n",
    "    test_x.grad.data /= int(test_x.shape[0]//batch_size)\n",
    "    grad = test_x.grad.data\n",
    "    grad = grad.view(grad.shape[0], -1).detach().cpu().numpy()\n",
    "    whitened = cluster.vq.whiten(grad)\n",
    "    print(\"Beginning Cluster\")\n",
    "    clust,distort = cluster.vq.kmeans(whitened, kmeans_k)\n",
    "    clust = clust.reshape(tuple([-1] + stim_shape))\n",
    "    fig=plt.figure(figsize=(18, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(\"Gradient Cluster with \" + str(kmeans_k)+\" means\", fontsize=16)\n",
    "    for i in range(kmeans_k):\n",
    "        std = np.std(clust[i])\n",
    "        mean = np.mean(clust[i])\n",
    "        vmin = mean - 1.9*std\n",
    "        vmax = mean + 1.9*std\n",
    "        n_slices = 8\n",
    "        for j in range(n_slices):\n",
    "            plt.subplot(kmeans_k,n_slices,1 + i*n_slices+j)\n",
    "            plt.imshow(clust[i,int(stim_shape[0]*j/n_slices),:,:], vmin=vmin, vmax=vmax)\n",
    "    plt.show()\n",
    "    ## Rank decomp\n",
    "    fig = plt.figure(figsize=(18,6))\n",
    "    fig.suptitle(\"Rank 1 Decomp of clusters\", fontsize=16)\n",
    "    for i in range(clust.shape[0]):\n",
    "        spatial_model, temporal_model = ft.decompose(clust[i])\n",
    "        plt.subplot(2,clust.shape[0], i+1)\n",
    "        plt.imshow(spatial_model, cmap = 'seismic', clim=[-np.max(abs(spatial_model)),\n",
    "                                                               np.max(abs(spatial_model))])\n",
    "        plt.subplot(2,clust.shape[0], i+1 + clust.shape[0])\n",
    "        plt.plot(temporal_model)\n",
    "    plt.show()\n",
    "\n",
    "    ## Give STA Ascent image\n",
    "    stas = []\n",
    "    sta_layer = \"sequential.\" + str(linear_idx)\n",
    "    print(\"Ascending STAs\")\n",
    "    for gang_cell in range(test_y.shape[-1]):\n",
    "        sta_img = sta_ascent_obj.sta_ascent(model, sta_layer, units=[gang_cell], n_epochs=10000)\n",
    "        stas.append(sta_img)\n",
    "        print(gang_cell, \"/\", test_y.shape[-1], end='\\r')\n",
    "    stas = np.asarray(stas).squeeze()\n",
    "    fig=plt.figure(figsize=(18, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(\"STA Ascent Image\", fontsize=16)\n",
    "    for i in range(len(stas)):\n",
    "        std = np.std(stas[i])\n",
    "        mean = np.mean(stas[i])\n",
    "        vmin = mean - 1.9*std\n",
    "        vmax = mean + 1.9*std\n",
    "        n_slices = 8\n",
    "        for j in range(n_slices):\n",
    "            plt.subplot(len(stas),n_slices, 1 + i*n_slices+j)\n",
    "            plt.imshow(stas[i,int(stim_shape[0]*j/n_slices),:,:], vmin=vmin, vmax=vmax)\n",
    "    plt.show()\n",
    "    # Rank decomp\n",
    "    plt.figure(figsize=(18,6))\n",
    "    fig.suptitle(\"Rank 1 Decomp of STA Ascent\", fontsize=16)\n",
    "    for i in range(stas.shape[0]):\n",
    "        spatial_model, temporal_model = ft.decompose(stas[i])\n",
    "        plt.subplot(2,stas.shape[0], i+1)\n",
    "        plt.imshow(spatial_model, cmap = 'seismic', clim=[-np.max(abs(spatial_model)),\n",
    "                                                               np.max(abs(spatial_model))])\n",
    "        plt.subplot(2,stas.shape[0], i+1 + stas.shape[0])\n",
    "        plt.plot(temporal_model)\n",
    "    plt.show()\n",
    "        \n",
    "    print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
