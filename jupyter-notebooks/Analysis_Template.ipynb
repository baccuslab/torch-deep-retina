{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import h5py as h5\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../\")\n",
    "from models import PracticalBNCNN, NormedBNCNN, DalesBNCNN, DalesSSCNN, SSCNN, BNCNN, PracticalBNCNN, DalesHybrid, DalesSkipBNCNN, SkipBNBNCNN\n",
    "#import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.deepretina_loader import loadexpt\n",
    "from utils.physiology import Physio\n",
    "import utils.intracellular as intracellular\n",
    "import utils.batch_compute as bc\n",
    "import utils.retinal_phenomena as rp\n",
    "import utils.stimuli as stimuli\n",
    "import pyret.filtertools as ft\n",
    "import scipy\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import resource\n",
    "import time\n",
    "import math\n",
    "\n",
    "def normalize(x):\n",
    "    return (x-x.mean())/(x.std()+1e-7)\n",
    "\n",
    "def retinal_phenomena_figs(bn_cnn):\n",
    "    rp.step_response(bn_cnn)\n",
    "    plt.save_fig(os.path.join(folder+\"_Analysis\", \"step_response.png\"))\n",
    "    rp.osr(bn_cnn)\n",
    "    plt.save_fig(os.path.join(folder+\"_Analysis\", \"osr.png\"))\n",
    "    rp.reversing_grating(bn_cnn)\n",
    "    plt.save_fig(os.path.join(folder+\"_Analysis\", \"reversing_grating.png\"))\n",
    "    rp.contrast_adaptation(bn_cnn, .35, .05)\n",
    "    plt.save_fig(os.path.join(folder+\"_Analysis\", \"contrast.png\"))\n",
    "    rp.motion_anticipation(bn_cnn)\n",
    "    plt.save_fig(os.path.join(folder+\"_Analysis\", \"motion_anticipation.png\"))\n",
    "    \n",
    "#If you want to use stimulus that isnt just boxes\n",
    "def prepare_stim(stim, stim_type):\n",
    "    if stim_type == 'boxes':\n",
    "        return 2*stim - 1\n",
    "    elif stim_type == 'flashes':\n",
    "        stim = stim.reshape(stim.shape[0], 1, 1)\n",
    "        return np.broadcast_to(stim, (stim.shape[0], 38, 38))\n",
    "    elif stim_type == 'movingbar':\n",
    "        stim = block_reduce(stim, (1,6), func=np.mean)\n",
    "        stim = pyret.stimulustools.upsample(stim.reshape(stim.shape[0], stim.shape[1], 1), 5)[0]\n",
    "        return np.broadcast_to(stim, (stim.shape[0], stim.shape[1], stim.shape[1]))\n",
    "    elif stim_type == 'lines':\n",
    "        stim_averaged = np.apply_along_axis(lambda m: np.convolve(m, 0.5*np.ones((2,)), mode='same'), \n",
    "                                            axis=1, arr=stim)\n",
    "        stim = stim_averaged[:,::2]\n",
    "        # now stack stimulus to convert 1d to 2d spatial stimulus\n",
    "        return stim.reshape(-1,1,stim.shape[-1]).repeat(stim.shape[-1], axis=1)\n",
    "    else:\n",
    "        print(\"Invalid stim type\")\n",
    "        assert False\n",
    "    \n",
    "def index_of(arg, arr):\n",
    "    for i in range(len(arr)):\n",
    "        if arg == arr[i]:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "# num_pots stores the number of cells per stimulus\n",
    "# mem_pots stores the membrane potential\n",
    "# psst, you can find the \"data\" folder in /home/grantsrb on deepretina server\n",
    "# psssst, note the additional ../ added to each path in files\n",
    "\n",
    "files = ['../data/bipolars_late_2012.h5', '../data/bipolars_early_2012.h5', '../data/amacrines_early_2012.h5', '../data/amacrines_late_2012.h5', '../data/horizontals_early_2012.h5', '../data/horizontals_late_2012.h5']\n",
    "files = [\"../\" + name for name in files]\n",
    "file_ids = []\n",
    "for f in files:\n",
    "    file_ids.append(re.split('_|\\.', f)[0])\n",
    "filter_length = 40\n",
    "window_size = 2\n",
    "num_pots = []\n",
    "stims = dict()\n",
    "mem_pots = dict()\n",
    "keys_to_use = {\"boxes\"}\n",
    "for fi in files:\n",
    "    with h5.File(fi, 'r') as f:\n",
    "        for k in f.keys():\n",
    "            if k in keys_to_use:\n",
    "                if k not in stims:\n",
    "                    stims[k] = []\n",
    "                if k not in mem_pots:\n",
    "                    mem_pots[k] = []\n",
    "                try:\n",
    "                    stims[k].append(prepare_stim(np.asarray(f[k+'/stimuli']), k))\n",
    "                    mem_pots[k].append(np.asarray(f[k]['detrended_membrane_potential'])[:, filter_length:])\n",
    "                except:\n",
    "                    print(\"stim error at\", k)\n",
    "        num = np.array(f['boxes/detrended_membrane_potential'].shape[0])\n",
    "        num_pots.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_folder = \"test\"\n",
    "exp_folder = \"../training_scripts/\"+grand_folder\n",
    "_, model_folders, _ = next(os.walk(exp_folder))\n",
    "for i,f in enumerate(model_folders):\n",
    "    model_folders[i] = grand_folder + \"/\" + f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folders = sorted(model_folders)\n",
    "print(\"\\n\".join(model_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../training_scripts/\"+model_folders[0]+\"/test_epoch_0.pth\"\n",
    "try:\n",
    "    with open(file, \"rb\") as fd:\n",
    "        temp = torch.load(fd)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "temp['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = ['sequential.2', 'sequential.8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = \"all\"\n",
    "dataset = '15-10-07'\n",
    "stim_type = 'naturalscene'\n",
    "norm_stats = [temp['norm_stats']['mean'], temp['norm_stats']['std']]\n",
    "test_data = loadexpt(dataset,cells,stim_type,'test',40,0, norm_stats=norm_stats)\n",
    "test_x = torch.from_numpy(test_data.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "max_mem_used = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "print(\"Memory Used: {:.2f} mb\".format(max_mem_used / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 250\n",
    "best_folder_by_loss = \"\"\n",
    "best_loss = 100\n",
    "best_folder_by_val_loss = \"\"\n",
    "best_val_loss = 100\n",
    "best_folder_by_val_acc = \"\"\n",
    "best_val_acc = -100\n",
    "best_folder_by_test_acc = \"\"\n",
    "best_test_acc = -100\n",
    "best_folder_by_intr_cor = \"\"\n",
    "best_intr_cor = -1\n",
    "\n",
    "results_file_name = grand_folder + \"_analysis_results.txt\"\n",
    "results_file = open(results_file_name, 'a')\n",
    "batch_compute_size = 2000\n",
    "model_stats = dict()\n",
    "\n",
    "# load the losses\n",
    "print(\"Using layers:\", \" and \".join(conv_layers))\n",
    "for folder in model_folders:\n",
    "    model_stats[folder] = dict()\n",
    "    starttime = time.time()\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    for i in range(n_epochs):\n",
    "        file = \"../training_scripts/\"+folder+\"/test_epoch_{0}.pth\".format(i)\n",
    "        try:\n",
    "            with open(file, \"rb\") as fd:\n",
    "                temp = torch.load(fd)\n",
    "            losses.append(temp['loss'])\n",
    "            val_losses.append(temp['val_loss'])\n",
    "            val_accs.append(temp['val_acc'])\n",
    "        except:\n",
    "            break\n",
    "    bn_cnn = temp['model']\n",
    "    bn_cnn = bn_cnn.to(DEVICE)\n",
    "    bn_cnn.eval()\n",
    "    print(\"Folder:\", folder)\n",
    "    results_file.write(folder + \"\\n\")\n",
    "    print(\"Final Loss:\", losses[-1])\n",
    "    results_file.write(\"Final Loss:\"+ str(losses[-1]) + \"\\n\")\n",
    "    model_stats[folder]['TrainLoss'] = losses[-1]\n",
    "    print(\"Final Val:\", val_losses[-1])\n",
    "    results_file.write(\"Final Val:\"+ str(val_losses[-1]) + \"\\n\")\n",
    "    model_stats[folder]['ValLoss'] = val_losses[-1]\n",
    "    print(\"Final Val Acc:\", val_accs[-1])\n",
    "    results_file.write(\"Val Acc:\"+ str(val_accs[-1]) + \"\\n\")\n",
    "    model_stats[folder]['ValAcc'] = val_accs[-1]\n",
    "    if(math.isnan(losses[-1]) or math.isnan(val_losses[-1]) or math.isnan(val_accs[-1])):\n",
    "        print(\"NaN results, continuing...\\n\\n\\n\\n\")\n",
    "        results_file.write(\"NaN results, continuing...\\n\\n\\n\\n\")\n",
    "        continue\n",
    "\n",
    "    model_response = bc.batch_compute_model_response(test_data.X, bn_cnn, batch_compute_size, \n",
    "                                                     insp_keys=set(conv_layers))    \n",
    "    avg_test_acc = np.mean([scipy.stats.pearsonr(model_response['output'][:, i], test_data.y[:, i])[0] \n",
    "                            for i in range(test_data.y.shape[-1])])\n",
    "    if math.isnan(avg_test_acc):\n",
    "        print(\"NaN results, continuing...\\n\\n\\n\\n\")\n",
    "        results_file.write(\"NaN results, continuing...\\n\\n\\n\\n\")\n",
    "        continue\n",
    "    print(\"\\nFinal Test Acc:\", avg_test_acc)\n",
    "    results_file.write(\"Final Test Acc:\"+ str(avg_test_acc) + \"\\n\")\n",
    "    model_stats[folder]['TestAcc'] = avg_test_acc\n",
    "    with open(\"../training_scripts/\"+folder+\"/hyperparams.txt\", 'a') as f:\n",
    "        f.write(\"\\nTest Ganglion Cell Correlation: \" + str(avg_test_acc))\n",
    "    if losses[-1] < best_loss:\n",
    "        best_loss = losses[-1]\n",
    "        best_folder_by_loss = folder\n",
    "    if val_losses[-1] < best_val_loss:\n",
    "        best_val_loss = val_losses[-1]\n",
    "        best_folder_by_val_loss = folder\n",
    "    if val_accs[-1] > best_val_acc:\n",
    "        best_val_acc = val_accs[-1]\n",
    "        best_folder_by_val_acc = folder\n",
    "    if avg_test_acc > best_test_acc:\n",
    "        best_test_acc = avg_test_acc\n",
    "        best_folder_by_test_acc = folder\n",
    "    plt.plot(normalize(model_response['output'][:400, 0]))\n",
    "    plt.plot(normalize(test_data.y[:400,0]), alpha=.7)\n",
    "    plt.legend([\"model\", \"data\"])\n",
    "    plt.title(\"Firing Rate\")\n",
    "    plt.show()\n",
    "    plt.save_fig(os.path.join(folder+\"_Analysis\", \"firingrate.png\"))\n",
    "    plt.plot(losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"TrainLoss\", \"ValLoss\"])\n",
    "    plt.title(\"Loss Curves\")\n",
    "    plt.ylim([-6, 6])\n",
    "    plt.show()\n",
    "    plt.save_fig(os.path.join(folder+\"_Analysis\", \"losscurves.png\"))\n",
    "    retinal_phenomena_figs(bn_cnn)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    if avg_test_acc < .5 or losses[-1] > 1:\n",
    "        print(\"Skipping further analysis due to poor results...\\n\\n\\n\\n\")\n",
    "        results_file.write(\"Skipping further analysis due to poor results...\\n\\n\\n\\n\")\n",
    "        continue\n",
    "    print(\"Calculating model responses...\\n\")\n",
    "    # Computes the model responses for each stimulus \n",
    "    # and interneuron type labels y_true (0 for bipolar, 1 for amacrine, 2 for horizontal)\n",
    "    y_true = []\n",
    "    filter_length = 40\n",
    "    model_responses = dict()\n",
    "    for i in tqdm(range(len(files))):\n",
    "        file_name = files[i]\n",
    "        if 'bipolar' in file_name:\n",
    "            for j in range(num_pots[i]):\n",
    "                y_true.append(0)\n",
    "        elif 'amacrine' in file_name:\n",
    "            for j in range(num_pots[i]):\n",
    "                y_true.append(1)\n",
    "        else:\n",
    "            for j in range(num_pots[i]):\n",
    "                y_true.append(2)\n",
    "        for k in stims.keys():\n",
    "            stim = stims[k][i]\n",
    "            padded_stim = intracellular.pad_to_edge(scipy.stats.zscore(stim))\n",
    "            if k not in model_responses:\n",
    "                model_responses[k] = []\n",
    "            model_responses[k].append(bc.batch_compute_model_response(stimuli.concat(padded_stim),\n",
    "                                                                      bn_cnn,batch_compute_size, \n",
    "                                                                      insp_keys=set(conv_layers)))\n",
    "            # Reshape potentially flat layers\n",
    "            for j,cl in enumerate(conv_layers):\n",
    "                if len(model_responses[k][-1][cl].shape) <= 2:\n",
    "                    try:\n",
    "                        model_responses[k][-1][cl] = model_responses[k][-1][cl].reshape((-1,8,36,36))\n",
    "                    except:\n",
    "                        model_responses[k][-1][cl] = model_responses[k][-1][cl].reshape((-1,8,26,26))\n",
    "    \n",
    "    # uses classify to get the most correlated cell/layer/subtype for each interneuron recording. \n",
    "    # Stored in all_cell_info. y_pred does a baseline \"classification\": record the convolutional \n",
    "    # layer that the most correlated cell is in.\n",
    "    # See intracellular.py for more info\n",
    "    # This takes a really long time to run. \n",
    "    print(\"Calculating intercellular correlations...\\n\")\n",
    "    all_cell_info = dict()\n",
    "    y_pred = dict()\n",
    "    for i in tqdm(range(len(files))):\n",
    "        for k in stims.keys():\n",
    "            model_response = model_responses[k][i]\n",
    "            stim = stims[k][i]\n",
    "            for j in range(mem_pots[k][i].shape[0]):\n",
    "                potential = mem_pots[k][i][j]\n",
    "                cell_info = intracellular.classify(potential, model_response, stim.shape[0], \n",
    "                                                   layer_keys=conv_layers)\n",
    "                #layer, channel,(row, col), cor_coef = cell_info\n",
    "                if k not in all_cell_info:\n",
    "                    all_cell_info[k] = []\n",
    "                    y_pred[k] = []\n",
    "                all_cell_info[k].append(cell_info)\n",
    "                y_pred[k].append(index_of(cell_info[0], conv_layers))\n",
    "    \n",
    "    model_stats[folder]['all_cell_info'] = all_cell_info\n",
    "    # Average intracellular correlation. RIP.\n",
    "    avg_intr_cor = np.mean(np.asarray([[all_cell_info[k][i][-1] for i in range(len(all_cell_info[k]))] for k in all_cell_info.keys()]))\n",
    "    print(\"Mean intracellular:\", avg_intr_cor)\n",
    "    results_file.write(\"Mean intracellular:\" + str(avg_intr_cor) + \"\\n\")\n",
    "    model_stats[folder]['IntrCor'] = avg_intr_cor\n",
    "    std = np.std(np.asarray([[all_cell_info[k][i][-1] for i in range(len(all_cell_info[k]))] for k in all_cell_info.keys()]))\n",
    "    print(\"Std intracellular:\", std)\n",
    "    m = np.min(np.asarray([[all_cell_info[k][i][-1] for i in range(len(all_cell_info[k]))] for k in all_cell_info.keys()]))\n",
    "    print(\"Min intracellular:\", m)\n",
    "    results_file.write(\"Min intracellular:\" + str(m) + \"\\n\")\n",
    "    m = np.max(np.asarray([[all_cell_info[k][i][-1] for i in range(len(all_cell_info[k]))] for k in all_cell_info.keys()]))\n",
    "    print(\"Max intracellular:\", m)\n",
    "    results_file.write(\"Max intracellular:\" + str(m) + \"\\n\")\n",
    "    \n",
    "    if avg_intr_cor > best_intr_cor:\n",
    "        best_intr_cor = avg_intr_cor\n",
    "        best_folder_by_intr_cor = folder\n",
    "    \n",
    "    stim_type = 'boxes'\n",
    "    # Make example correlation map\n",
    "    model_response = model_responses[stim_type][-1]\n",
    "    potential = mem_pots[stim_type][-1][-1]\n",
    "    layer, k, (i,j), r = all_cell_info[stim_type][-1]\n",
    "    print(\"Layer\", layer, \"correlation map\")\n",
    "    plt.imshow(intracellular.correlation_map(potential, model_response[layer][:, k]))\n",
    "    plt.show()\n",
    "\n",
    "    keys = ['bipolar', 'amacrine', 'horizontal']\n",
    "    layer_dict = {}\n",
    "    # Tally layers for maximally correlated cell\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] not in layer_dict:\n",
    "            layer_dict[y_true[i]] = [0 for i in range(len(conv_layers))]\n",
    "        for k in y_pred.keys():\n",
    "            layer_dict[y_true[i]][y_pred[k][i]] += 1\n",
    "\n",
    "    width = 0.5\n",
    "    lkeys = list(layer_dict.keys())\n",
    "    ind = np.arange(0,len(conv_layers))\n",
    "    for i,k in enumerate(lkeys):\n",
    "        plt.bar(ind, [count for count in layer_dict[k]], width)\n",
    "        plt.xticks(ind,conv_layers)\n",
    "        print(keys[i])\n",
    "        plt.title(\"Layer of unit with max correlation\")\n",
    "        plt.show()\n",
    "    \n",
    "    stimulus_num = 3\n",
    "    filter_length = 40\n",
    "    for type_key in stims.keys():\n",
    "        if type_key == \"flashes\":\n",
    "            continue\n",
    "        stimulus = stims[type_key][stimulus_num]\n",
    "        # Plot the receptive field for a model cell\n",
    "        for i,cl in enumerate(conv_layers):\n",
    "            model_cell_response = model_responses[type_key][stimulus_num][cl][:, 1, 15, 15]\n",
    "            print(\"Receptive field of\", type_key,\"model cell in Layer\", i)\n",
    "            rc_model, lags_model = ft.revcorr(scipy.stats.zscore(stimulus)[filter_length:], model_cell_response, \n",
    "                                              nsamples_before=0, nsamples_after=filter_length)\n",
    "            spatial_model, temporal_model = ft.decompose(rc_model)\n",
    "            img = plt.imshow(spatial_model, cmap = 'seismic', clim=[-np.max(abs(spatial_model)), \n",
    "                                                                   np.max(abs(spatial_model))])\n",
    "            plt.show()\n",
    "    \n",
    "    gc.collect()\n",
    "    max_mem_used = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "    print(\"Memory Used: {:.2f} memory\".format(max_mem_used / 1024))\n",
    "    print(\"Completed in\", time.time()-starttime, \"seconds\")\n",
    "    print(\"\\n\\n\\n\\n\")\n",
    "    results_file.write(\"\\n\\n\\n\\n\")\n",
    "                    \n",
    "print(\"Best by validation loss:\", best_folder_by_val_loss)\n",
    "print(\" - \".join([k+\":\"+str(model_stats[best_folder_by_val_loss][k]) if k != \"all_cell_info\" else \"\" \n",
    "                  for k in model_stats[best_folder_by_val_loss].keys()]))\n",
    "print(\"Best by training loss:\", best_folder_by_loss)\n",
    "print(\" - \".join([k+\":\"+str(model_stats[best_folder_by_loss][k]) if k != \"all_cell_info\" else \"\" \n",
    "                  for k in model_stats[best_folder_by_loss].keys()]))\n",
    "print(\"Best by val accuracy:\", best_folder_by_val_acc)\n",
    "print(\" - \".join([k+\":\"+str(model_stats[best_folder_by_val_acc][k]) if k != \"all_cell_info\" else \"\" \n",
    "                  for k in model_stats[best_folder_by_val_acc].keys()]))\n",
    "print(\"Best by test accuracy:\", best_folder_by_test_acc)\n",
    "print(\" - \".join([k+\":\"+str(model_stats[best_folder_by_test_acc][k]) if k != \"all_cell_info\" else \"\" \n",
    "                  for k in model_stats[best_folder_by_test_acc].keys()]))\n",
    "print(\"Best by intracellular correlation:\", best_folder_by_intr_cor)\n",
    "print(\" - \".join([k+\":\"+str(model_stats[best_folder_by_intr_cor][k]) if k != \"all_cell_info\" else \"\" \n",
    "                  for k in model_stats[best_folder_by_intr_cor].keys()]))\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptive fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = best_folder_by_test_acc\n",
    "for i in range(300):\n",
    "    file = \"../training_scripts/\"+folder+\"/test_epoch_{0}.pth\".format(i)\n",
    "    try:\n",
    "        with open(file, \"rb\") as fd:\n",
    "            temp = torch.load(fd)\n",
    "    except:\n",
    "        break\n",
    "bn_cnn = temp['model']\n",
    "bn_cnn = bn_cnn.to(DEVICE)\n",
    "bn_cnn.eval()\n",
    "    \n",
    "y_true = []\n",
    "filter_length = 40\n",
    "model_responses = dict()\n",
    "for i in tqdm(range(len(files))):\n",
    "    file_name = files[i]\n",
    "    if 'bipolar' in file_name:\n",
    "        for j in range(num_pots[i]):\n",
    "            y_true.append(0)\n",
    "    elif 'amacrine' in file_name:\n",
    "        for j in range(num_pots[i]):\n",
    "            y_true.append(1)\n",
    "    else:\n",
    "        for j in range(num_pots[i]):\n",
    "            y_true.append(2)\n",
    "    for k in stims.keys():\n",
    "        stim = stims[k][i]\n",
    "        padded_stim = intracellular.pad_to_edge(scipy.stats.zscore(stim))\n",
    "        if k not in model_responses:\n",
    "            model_responses[k] = []\n",
    "        model_responses[k].append(bc.batch_compute_model_response(stimuli.concat(padded_stim),\n",
    "                                                                  bn_cnn,batch_compute_size, \n",
    "                                                                  insp_keys=set(conv_layers)))\n",
    "        # Reshape potentially flat layers\n",
    "        for j,cl in enumerate(conv_layers):\n",
    "            if len(model_responses[k][-1][cl].shape) <= 2:\n",
    "                try:\n",
    "                    model_responses[k][-1][cl] = model_responses[k][-1][cl].reshape((-1,8,36,36))\n",
    "                except:\n",
    "                    model_responses[k][-1][cl] = model_responses[k][-1][cl].reshape((-1,8,26,26))\n",
    "\n",
    "stimulus_num = 0\n",
    "stim_type = 'boxes'\n",
    "for layer in conv_layers:\n",
    "    for fil in range(8):\n",
    "        print(layer,\"Filter:\", fil)\n",
    "        f = plt.figure(figsize=(50, 50))\n",
    "        pos=1\n",
    "        for i in range(0,26,4):\n",
    "            for j in range(0,26,4):\n",
    "                stimulus_num = 0\n",
    "                model_cell_response = model_responses[stim_type][stimulus_num][layer][:, fil, i, j]\n",
    "                stimulus = stims[stim_type][stimulus_num]\n",
    "                filter_length = 40\n",
    "                f.add_subplot(7, 7, pos)\n",
    "                rc_model, lags_model = ft.revcorr(scipy.stats.zscore(stimulus)[filter_length:], model_cell_response, nsamples_before=0, nsamples_after=filter_length)\n",
    "                spatial_model, temporal_model = ft.decompose(rc_model)\n",
    "                img =plt.imshow(spatial_model, cmap = 'seismic', clim=[-np.max(abs(spatial_model)), np.max(abs(spatial_model))])\n",
    "                pos += 1\n",
    "        if layer == conv_layers[0]:\n",
    "            plt.savefig('images/model1_layer1_{0}'.format(fil))\n",
    "        else:\n",
    "            plt.savefig('images/model1_layer2_{0}'.format(fil))\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
